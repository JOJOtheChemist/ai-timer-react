#!/usr/bin/env python3
"""
ç®€åŒ–çš„æµ‹è¯•æœåŠ¡å™¨ - ä»…ç”¨äºæµ‹è¯•AIç›¸å…³API
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
import uvicorn

# åˆ›å»ºFastAPIåº”ç”¨å®ä¾‹
app = FastAPI(
    title="AI Time Backend API - Test Server",
    description="AI APIæµ‹è¯•æœåŠ¡å™¨",
    version="1.0.0"
)

# é…ç½®CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ ¹è·¯ç”±
@app.get("/")
async def root():
    return {"message": "AI API Test Server", "version": "1.0.0", "status": "running"}

# å¥åº·æ£€æŸ¥è·¯ç”±
@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "API is running"}

# åªå¯¼å…¥AIç›¸å…³çš„è·¯ç”±
try:
    from api.v1.endpoints.ai import ai_chat
    app.include_router(ai_chat.router, prefix="/api/v1/ai", tags=["AIèŠå¤©"])
    print("âœ… AI Chat router loaded")
except Exception as e:
    print(f"âš ï¸  Failed to load AI Chat router: {e}")
    import traceback
    traceback.print_exc()

try:
    from api.v1.endpoints.ai import ai_recommendations
    app.include_router(ai_recommendations.router, prefix="/api/v1/ai", tags=["AIæ¨è"])
    print("âœ… AI Recommendations router loaded")
except Exception as e:
    print(f"âš ï¸  Failed to load AI Recommendations router: {e}")
    import traceback
    traceback.print_exc()

# å…¨å±€å¼‚å¸¸å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    return JSONResponse(
        status_code=500,
        content={"message": "Internal server error", "detail": str(exc)}
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨AI APIæµ‹è¯•æœåŠ¡å™¨")
    print("=" * 60)
    uvicorn.run(
        "test_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        log_level="info"
    ) 