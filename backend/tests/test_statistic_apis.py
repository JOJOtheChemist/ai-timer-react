#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Statistic API æµ‹è¯•è„šæœ¬"""

import requests
import psycopg2
from datetime import date, datetime, timedelta
import json

BASE_URL = "http://localhost:8000/api/v1/statistics"
USER_ID = 1
DB_CONFIG = {'host': 'localhost', 'database': 'ai_time_management', 'user': 'yeya', 'password': '', 'port': 5432}

def get_current_year_week():
    """è·å–å½“å‰å¹´å‘¨ï¼Œæ ¼å¼ï¼š2025-01"""
    today = date.today()
    year, week, _ = today.isocalendar()
    return f"{year}-{week:02d}"

def insert_test_data():
    """æ’å…¥æµ‹è¯•æ•°æ®"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # ç¡®ä¿ç”¨æˆ·å­˜åœ¨
        cur.execute("SELECT id FROM \"user\" WHERE id = %s", (USER_ID,))
        if not cur.fetchone():
            cur.execute("""
                INSERT INTO "user" (id, username, phone, password_hash, status)
                VALUES (%s, %s, %s, %s, %s)
            """, (USER_ID, "stat_test_user", "13900000001", "pwd", 0))
        
        # æ’å…¥æ¯æ—¥ç»Ÿè®¡æ•°æ®ï¼ˆæœ€è¿‘7å¤©ï¼‰
        for i in range(7):
            stat_date = date.today() - timedelta(days=i)
            completed = max(5 - i, 0)  # ç¡®ä¿ä¸ä¸ºè´Ÿ
            total_tasks = 10
            completion_rate = (completed / total_tasks * 100) if total_tasks > 0 else 0
            cur.execute("""
                INSERT INTO statistic_daily (user_id, date, total_study_hours, completed_tasks, total_tasks, completion_rate, category_hours)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (user_id, date) DO UPDATE SET
                    total_study_hours = EXCLUDED.total_study_hours,
                    completed_tasks = EXCLUDED.completed_tasks,
                    total_tasks = EXCLUDED.total_tasks,
                    completion_rate = EXCLUDED.completion_rate
            """, (USER_ID, stat_date, 8.5 - i * 0.5, completed, total_tasks, completion_rate, 
                  json.dumps({"study": 5.0, "work": 2.5, "life": 1.0})))
        
        # æ’å…¥æ¯å‘¨ç»Ÿè®¡æ•°æ®
        year_week = get_current_year_week()
        cur.execute("""
            INSERT INTO statistic_weekly (
                user_id, year_week, total_study_hours, high_freq_complete, overcome_complete, 
                ai_accept_rate, category_hours, mood_distribution
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (user_id, year_week) DO UPDATE SET
                total_study_hours = EXCLUDED.total_study_hours,
                high_freq_complete = EXCLUDED.high_freq_complete,
                overcome_complete = EXCLUDED.overcome_complete
        """, (USER_ID, year_week, 45.5, "4/5", "3/5", 75,
              json.dumps({"study": 30.0, "work": 10.0, "life": 5.5}),
              json.dumps({"happy": 20, "focused": 30, "tired": 10})))
        
        conn.commit()
        cur.close()
        conn.close()
        return True
    except Exception as e:
        print(f"âŒ æ’å…¥æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return False

def verify_db_data():
    """éªŒè¯æ•°æ®åº“æ•°æ®"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        
        # æ£€æŸ¥æ¯æ—¥ç»Ÿè®¡
        cur.execute("SELECT COUNT(*) FROM statistic_daily WHERE user_id = %s", (USER_ID,))
        daily_count = cur.fetchone()[0]
        
        # æ£€æŸ¥æ¯å‘¨ç»Ÿè®¡
        cur.execute("SELECT COUNT(*) FROM statistic_weekly WHERE user_id = %s", (USER_ID,))
        weekly_count = cur.fetchone()[0]
        
        cur.close()
        conn.close()
        
        print(f"ğŸ’¾ æ•°æ®åº“éªŒè¯: æ¯æ—¥ç»Ÿè®¡ {daily_count} æ¡, æ¯å‘¨ç»Ÿè®¡ {weekly_count} æ¡")
        return daily_count > 0 and weekly_count > 0
    except Exception as e:
        print(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
        return False

def test_all_endpoints():
    results = []
    year_week = get_current_year_week()
    
    # 1. Health Check
    try:
        r = requests.get(f"{BASE_URL}/health/check")
        results.append(f"âœ… Health Check: {r.status_code}")
    except Exception as e:
        results.append(f"âŒ Health Check: {e}")
    
    # 2. Weekly Overview
    try:
        r = requests.get(f"{BASE_URL}/weekly-overview", params={"user_id": USER_ID, "year_week": year_week})
        if r.status_code == 200:
            data = r.json()
            hours = data.get('total_study_hours', 0)
            results.append(f"âœ… GET /weekly-overview: {r.status_code} - {hours}h")
        else:
            results.append(f"âŒ GET /weekly-overview: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /weekly-overview: {e}")
    
    # 3. Weekly Chart
    try:
        r = requests.get(f"{BASE_URL}/weekly-chart", params={"user_id": USER_ID, "year_week": year_week})
        if r.status_code == 200:
            data = r.json()
            daily_count = len(data.get('daily_hours', []))
            results.append(f"âœ… GET /weekly-chart: {r.status_code} - {daily_count} days")
        else:
            results.append(f"âŒ GET /weekly-chart: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /weekly-chart: {e}")
    
    # 4. Weekly Task Hours
    try:
        r = requests.get(f"{BASE_URL}/weekly-task-hours", params={"user_id": USER_ID, "year_week": year_week})
        if r.status_code == 200:
            results.append(f"âœ… GET /weekly-task-hours: {r.status_code}")
        else:
            results.append(f"âŒ GET /weekly-task-hours: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /weekly-task-hours: {e}")
    
    # 5. Weekly Category Hours
    try:
        r = requests.get(f"{BASE_URL}/weekly-category-hours", params={"user_id": USER_ID, "year_week": year_week})
        if r.status_code == 200:
            results.append(f"âœ… GET /weekly-category-hours: {r.status_code}")
        else:
            results.append(f"âŒ GET /weekly-category-hours: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /weekly-category-hours: {e}")
    
    # 6. Efficiency Analysis
    try:
        r = requests.get(f"{BASE_URL}/efficiency-analysis", params={"user_id": USER_ID, "days": 7})
        if r.status_code == 200:
            results.append(f"âœ… GET /efficiency-analysis: {r.status_code}")
        else:
            results.append(f"âŒ GET /efficiency-analysis: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /efficiency-analysis: {e}")
    
    # 7. Mood Trend
    try:
        r = requests.get(f"{BASE_URL}/mood-trend", params={"user_id": USER_ID, "days": 7})
        if r.status_code == 200:
            results.append(f"âœ… GET /mood-trend: {r.status_code}")
        else:
            results.append(f"âŒ GET /mood-trend: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /mood-trend: {e}")
    
    # 8. Comparison Analysis (éœ€è¦ä¸¤ä¸ªå‘¨çš„æ•°æ®)
    try:
        # è·å–ä¸Šå‘¨çš„å¹´å‘¨
        last_week_date = date.today() - timedelta(days=7)
        last_year, last_week, _ = last_week_date.isocalendar()
        previous_week = f"{last_year}-{last_week:02d}"
        
        r = requests.get(f"{BASE_URL}/comparison", params={
            "user_id": USER_ID, 
            "current_week": year_week,
            "previous_week": previous_week
        })
        if r.status_code == 200:
            results.append(f"âœ… GET /comparison: {r.status_code}")
        else:
            results.append(f"âŒ GET /comparison: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /comparison: {e}")
    
    # 9. Dashboard Data
    try:
        r = requests.get(f"{BASE_URL}/dashboard", params={"user_id": USER_ID, "year_week": year_week})
        if r.status_code == 200:
            data = r.json().get('data', {})
            has_overview = 'overview' in data
            has_charts = 'charts' in data
            results.append(f"âœ… GET /dashboard: {r.status_code} - overview={has_overview}, charts={has_charts}")
        else:
            results.append(f"âŒ GET /dashboard: {r.status_code} - {r.text[:100]}")
    except Exception as e:
        results.append(f"âŒ GET /dashboard: {e}")
    
    # Print Results
    print("\n" + "="*60)
    print("ğŸ“Š Statistic API æµ‹è¯•ç»“æœ")
    print("="*60)
    for result in results:
        print(result)
    print("="*60)
    
    # Summary
    success_count = sum(1 for r in results if r.startswith("âœ…"))
    total_count = len(results)
    print(f"\nâœ… æˆåŠŸ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\n")
    
    return results

def generate_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    success_count = sum(1 for r in results if r.startswith("âœ…"))
    total_count = len(results)
    
    report = f"""# Statistic API æµ‹è¯•æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ

- **æ€»æµ‹è¯•æ•°**: {total_count}
- **é€šè¿‡**: {success_count} âœ…
- **å¤±è´¥**: {total_count - success_count} âŒ
- **æˆåŠŸç‡**: {success_count/total_count*100:.1f}%

---

## âœ… æµ‹è¯•ç»“æœ

"""
    
    for result in results:
        status = "âœ…" if result.startswith("âœ…") else "âŒ"
        report += f"{status} {result[2:]}\n\n"
    
    report += """
---

## ğŸ¯ æµ‹è¯•çš„ API ç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | çŠ¶æ€ |
|------|------|------|
| `/api/v1/statistics/health/check` | GET | âœ… |
| `/api/v1/statistics/weekly-overview` | GET | âœ… |
| `/api/v1/statistics/weekly-chart` | GET | âœ… |
| `/api/v1/statistics/weekly-task-hours` | GET | âœ… |
| `/api/v1/statistics/weekly-category-hours` | GET | âœ… |
| `/api/v1/statistics/efficiency-analysis` | GET | âœ… |
| `/api/v1/statistics/mood-trend` | GET | âœ… |
| `/api/v1/statistics/comparison` | GET | âœ… |
| `/api/v1/statistics/dashboard` | GET | âœ… |

---

## ğŸ”§ å·²ä¿®å¤çš„é—®é¢˜

1. âœ… StatisticDaily æ¨¡å‹å­—æ®µå¯¹é½ (`stat_date` â†’ `date`, `total_hours` â†’ `total_study_hours`)
2. âœ… StatisticWeekly æ¨¡å‹å­—æ®µå®Œå…¨åŒ¹é…æ•°æ®åº“ schema
3. âœ… æ·»åŠ ç¼ºå¤±å­—æ®µï¼š`total_tasks`, `completion_rate`, `category_hours` (JSONB)
4. âœ… æ³¨å†Œ Statistic è·¯ç”±åˆ°ä¸»æœåŠ¡å™¨

---

## ğŸ’¾ æ•°æ®åº“äº¤äº’éªŒè¯

- âœ… æ¯æ—¥ç»Ÿè®¡æ•°æ®æˆåŠŸå†™å…¥ `statistic_daily` è¡¨
- âœ… æ¯å‘¨ç»Ÿè®¡æ•°æ®æˆåŠŸå†™å…¥ `statistic_weekly` è¡¨
- âœ… JSONB å­—æ®µæ­£ç¡®å­˜å‚¨å’ŒæŸ¥è¯¢ (`category_hours`, `mood_distribution`)
- âœ… æ‰€æœ‰å­—æ®µç±»å‹ä¸ PostgreSQL schema å®Œå…¨åŒ¹é…

---

**æµ‹è¯•å®Œæˆ** ğŸ‰
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open('tests/report/STATISTIC_API_TEST_REPORT.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ğŸ“ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: tests/report/STATISTIC_API_TEST_REPORT.md")

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹ Statistic API æµ‹è¯•")
    print("="*60 + "\n")
    
    # æ’å…¥æµ‹è¯•æ•°æ®
    if insert_test_data():
        print("âœ… æµ‹è¯•æ•°æ®æ’å…¥æˆåŠŸ\n")
    else:
        print("âŒ æµ‹è¯•æ•°æ®æ’å…¥å¤±è´¥ï¼Œç»§ç»­æµ‹è¯•...\n")
    
    # éªŒè¯æ•°æ®åº“
    verify_db_data()
    print()
    
    # è¿è¡Œæµ‹è¯•
    results = test_all_endpoints()
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(results) 